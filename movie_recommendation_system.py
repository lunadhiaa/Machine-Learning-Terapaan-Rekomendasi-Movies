# -*- coding: utf-8 -*-
"""Movie Recommendation System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11JW13dXkL9M1RwKHbUsJ64rW1_6tKrWW

## **Proyek Machine Learning - Lulu Nadhiatun Anisa** ##

---

![Image Apel](https://cdn.antaranews.com/cache/1200x800/2022/02/04/Screenshot_2022-02-04-06-04-11-69_copy_1024x683.jpg)

## **Project Overview**

### **Latar Belakang Rekomendasi Film dengan Machine Lerning**


Di era digital, akses informasi yang melimpah melalui internet telah mengubah cara masyarakat memenuhi kebutuhan hiburan, termasuk dalam menonton film. Setiap harinya, jumlah data yang tersedia terus bertambah, memberikan peluang bagi perusahaan untuk memahami preferensi pelanggan secara lebih mendalam. Salah satu solusi yang berkembang dari pemanfaatan data ini adalah sistem rekomendasi, yang dirancang untuk memberikan saran yang relevan dan personal kepada pengguna berdasarkan pola perilaku mereka.  Proyek ini bertujuan untuk mengembangkan model machine learning yang dapat membuat Sistem rekomendasi film. Sistem rekomendasi film merupakan sistem yang merekomendasikan film kepada penonton atau pengguna lainnya. Sistem rekomendasi ini dibuat dengan peferensi kesukaan pengguna dimasa lalu, serta rating dari movie tersebut. Pengembangan model machine learning yang efektif untuk sistem rekomendasi Film dapat menjadi solusi yang inovatif untuk menghadapi tantangan informasi berlimpah dan memberikan pengalaman menyenangkan pengguna.

# **Rekomendasi Sistem: Film**
"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/gdrive/MyDrive/Active/ML-TERAPAN/submission2'

"""## 1. Import Library

Import library berarti mengambil atau menggunakan fungsi, kelas, atau modul tertentu yang telah didefinisikan sebelumnya dalam pustaka (library).
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from pathlib import Path
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

"""## 2. Data Understanding

Data Understanding merupakan proses memahami informasi dalam data dan menentukan kualitas dari data tersebut.

<br>

**Informasi Datasets**


| Jenis | Keterangan |
| ------ | ------ |
| Title | Movie Recommendation Data |
| Source | [Kaggle](https://www.kaggle.com/datasets/rohan4050/movie-recommendation-data) |
| Maintainer | [Rohan Sharma  ⚡](https://www.kaggle.com/rohan4050) |
| License | Other (specified in description) |
| Visibility | Publik |
| Tags | Movie and TV Show, Recommender System |
| Usability | 10.00 |

Membaca dataset yang akan digunakan dengan menggunakan fungsi pandas yaitu pd.read_csv
"""

movies = pd.read_csv('/content/gdrive/MyDrive/Active/ML-TERAPAN/submission2/small-data/movies.csv') #data film
ratings = pd.read_csv('/content/gdrive/MyDrive/Active/ML-TERAPAN/submission2/small-data/ratings.csv') #data ratings film
tags = pd.read_csv('/content/gdrive/MyDrive/Active/ML-TERAPAN/submission2/small-data/tags.csv') # data tag film
links = pd.read_csv('/content/gdrive/MyDrive/Active/ML-TERAPAN/submission2/small-data/links.csv') #data links setiap film

"""Melihat jumlah unique dari masing-masing data"""

# check and count unique values in each dataframes
print('Jumlah data film: ', len(movies.movieId.unique()))
print('Jumlah data ratings dari user: ', len(ratings.userId.unique()))
print('Jumlah data ratings dari film : ', len(ratings.movieId.unique()))
print('Jumlah data tags film: ', len(tags.userId.unique()))
print('Jumlah data links film: ', len(links.movieId.unique()))
print('Jumlah data : ', len(tags.movieId.unique()))

"""Variabel yang ada pada dataset movie-recommendation-data adalah sebagai berikut :

- movies : merupakan daftar movie yang tersedia.
- ratings : merupakan daftar penilaian yang diberikan pengguna terhadap movie.
- tags : merupakan daftar kata kunci dari movie tersebut
- links : merupakan daftar link movie tersebut.

### Movies
Eksplorasi variabel movies yang merupakan daftar movie yang tersedia.

#### Menampilkan dataset
"""

movies

"""Pada file `movies.csv` berisi daftar film yang memiliki 3 feature:

- `movieId` : memuat nomor ID film  
- `title` : memuat judul film
- `genres` : memuat genre film

#### Informasi dataset
"""

movies.info()

"""Fungsi `.info()` digunakan untuk memberikan deskripsi umum tentang DataFrame, termasuk tipe data, jumlah kolom, jumlah baris, apakah ada nilai kosong (missing values), dan penggunaan memori.

#### Melihat jumlah baris dan kolom
"""

movies.shape

"""Dari dataset movies diatas yang digunakan berjumlah 9742 baris dengan 3 kolom didalamnya.

#### Deskripsi Dataset
"""

movies.describe()

"""Fungsi `describe()` memberikan informasi statistik pada masing-masing kolom, antara lain:

- `Count` adalah jumlah sampel pada data.
- `Mean` adalah nilai rata-rata.
- `Std` adalah standar deviasi.
- `Min` yaitu nilai minimum setiap kolom.
- `25%` adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- `50%` adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
-` 75%` adalah kuartil ketiga.
- `Max` adalah nilai maksimum.

### Ratings
Eksplorasi data yang akan digunakan pada model yaitu data ratings.

#### Menampilkan dataset
"""

ratings

"""Pada file `ratings.csv` berisi daftar ratings atau penilaian terhadap satu film yang memiliki 4 feature:

- `userId` : memuat nomor ID users
- `movieId` : memuat nomor ID film  
- `rating` : memuat rating atau penilaian films dalam skala bintang, dengan peningkatan setengah bintang dalam rentang 0,5 - 5 bintang
- `timestamp` : memuat kode timestamp

#### Informasi dataset
"""

ratings.info()

"""Fungsi `.info()` digunakan untuk memberikan deskripsi umum tentang DataFrame, termasuk tipe data, jumlah kolom, jumlah baris, apakah ada nilai kosong (missing values), dan penggunaan memori.

#### Menampilkan jumlah baris dan kolom
"""

ratings.shape

"""Dari dataset ratings di atas yang digunakan berjumlah 100836 baris dengan 3 kolom didalamnya.

#### Deskripsi Dataset
"""

ratings.describe()

"""Fungsi `describe()` memberikan informasi statistik pada masing-masing kolom, antara lain:

- `Count` adalah jumlah sampel pada data.
- `Mean` adalah nilai rata-rata.
- `Std` adalah standar deviasi.
- `Min` yaitu nilai minimum setiap kolom.
- `25%` adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- `50%` adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
-` 75%` adalah kuartil ketiga.
- `Max` adalah nilai maksimum.

### Tags
Eksplorasi variabel Tags, merupakan tags masing-masing movie tersebut.

#### Menampilkan dataset
"""

tags

"""Pada file `tags.csv` berisi daftar tags pada film yang diberikan users yang memiliki 4 feature:

- `userId` : memuat nomor ID users
- `movieId` : memuat nomor ID film  
- `tag` : memuat tag film
- `timestamp` : memuat kode timestamp

#### Informasi dataset
"""

tags.info()

"""Fungsi `.info()` digunakan untuk memberikan deskripsi umum tentang DataFrame, termasuk tipe data, jumlah kolom, jumlah baris, apakah ada nilai kosong (missing values), dan penggunaan memori.

#### Menampilkan jumlah baris dan kolom
"""

tags.shape

"""Dari dataset tags di atas yang digunakan berjumlah 3683 baris dengan 4 kolom didalamnya.

#### Deskripsi Dataset
"""

tags.describe()

"""Fungsi `describe()` memberikan informasi statistik pada masing-masing kolom, antara lain:

- `Count` adalah jumlah sampel pada data.
- `Mean` adalah nilai rata-rata.
- `Std` adalah standar deviasi.
- `Min` yaitu nilai minimum setiap kolom.
- `25%` adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- `50%` adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
-` 75%` adalah kuartil ketiga.
- `Max` adalah nilai maksimum.

### Links
Eksplorasi variabel links, merupakan daftar link movie tersebut.

#### Menampilkan dataset
"""

links

"""Pada file `links.csv` berisi daftar links film yang mengarah ke laman website films 3 feature:

- `movieId` : memuat nomor ID film yang merujuk pada website MovieLens
- `imdbId` : memuat nomor ID film yang merujuk pada website IMDb
- `tmdbId` : memuat nomor ID film yang merujuk pada website TMDB

#### Informasi dataset
"""

links.info()

"""Fungsi `.info()` digunakan untuk memberikan deskripsi umum tentang DataFrame, termasuk tipe data, jumlah kolom, jumlah baris, apakah ada nilai kosong (missing values), dan penggunaan memori.

#### Menampilkan jumlah baris dan kolom
"""

links.shape

"""Dari dataset links di atas yang digunakan berjumlah 9742 baris dengan 3 kolom didalamnya.

#### Deskripsi Dataset
"""

links.describe()

"""Fungsi `describe()` memberikan informasi statistik pada masing-masing kolom, antara lain:

- `Count` adalah jumlah sampel pada data.
- `Mean` adalah nilai rata-rata.
- `Std` adalah standar deviasi.
- `Min` yaitu nilai minimum setiap kolom.
- `25%` adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval dalam empat bagian sebaran yang sama.
- `50%` adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
-` 75%` adalah kuartil ketiga.
- `Max` adalah nilai maksimum.

## 3. Data Preprocessing

### Menggabungkan MovieId
Menggabungkan seluruh ID film (movieId) dari berbagai kategori data yang ada di beberapa dataframe, yaitu links, movies, ratings, dan tags. Penggabungan ini menggunakan fungsi `np.concatenate` Dengan menggabungkannya pada variabel movie_all
"""

movie_all = np.concatenate((
    links.movieId.unique(),
    movies.movieId.unique(),
    ratings.movieId.unique(),
    tags.movieId.unique(),
))

# Mengurutkan data dan menghapus data yang sama
movie_all = np.sort(np.unique(movie_all))
print('Jumlah seluruh data movie berdasarkan movieID: ', len(movie_all))

"""### Menggabungkan UserId
Menggabungkan seluruh ID pengguna (userId) yang ada dalam dua dataframe, yaitu ratings dan tags, Penggabungan ini menggunakan fungsi `np.concatenate`. Dengan menggabungkannya pada variabel user_all
"""

user_all = np.concatenate((
    ratings.userId.unique(),
    tags.userId.unique(),
))

# Menghapus data yang sama kemudian mengurutkannya
user_all = np.sort(np.unique(user_all))
print('Jumlah seluruh user: ', len(user_all))

"""### Menggabungkan Links, Movies, Ratings, Dan Tags

Menggabungkan empat dataframe (links, movies, ratings, dan tags) menjadi satu dataframe menggunakan fungsi `pd.concat()`
"""

movie_info = pd.concat([links, movies, ratings, tags])

"""### Menggabungkan Dataframe ratings Dengan movie_info Berdasarkan Nilai movieId

Menggabungkan dua dataframe, yaitu ratings dan movie_info, berdasarkan kolom movieId, dengan metode penggabungan `pd.merge`
"""

movie = pd.merge(ratings, movie_info , on='movieId', how='left')

movie

"""Seperti yang terlihat dari hasil sebelumnya, terdapat banyak nilai yang hilang (missing value). Oleh karena itu,dapat melakukan pemeriksaan untuk mengidentifikasi missing value tersebut.

Memeriksa dan menghitung jumlah nilai yang hilang (missing values) atau NaN di setiap kolom dalam dataframe movie
"""

movie.isnull().sum()

"""Menggabungkan data dalam dataframe movie berdasarkan kolom movieId,"""

movie.groupby('movieId').sum()

"""### Menggabungkan Data Dengan Featuers Movie

Mendefinisikan variabel all_movie_rates dengan variabel ratings
"""

all_movie_rates = ratings
all_movie_rates

"""Menggabungkan all movie_rates dengan dataframe movies berdasarkan movieId memaluli variabel all_movie_name"""

all_movie_name = pd.merge(all_movie_rates, movies[['movieId','title','genres']], on='movieId', how='left')
all_movie_name

"""Menggabungkan dataframe tags dengan all_movie_name berdasarkan movieId dan memasukkannya ke dalam variabel all_movies"""

# Menggabungkan dataframe genres dengan all_movie_name dan memasukkannya ke dalam variabel all_movie
all_movies = pd.merge(all_movie_name, tags[['movieId','tag']], on='movieId', how='left')
all_movies

"""## 3. Data Preparation

#### Missing Value
Missing values atau nilai yang hilang adalah data yang tidak tersedia atau kosong dalam sebuah dataset.
"""

all_movies.isnull().sum()

"""Berdasarkan data yang ditemukan, terdapat 52.549 nilai kosong pada kolom tag. Oleh karena itu, pembersihan missing value dilakukan menggunakan fungsi dropna(). Fungsi ini akan menghapus baris yang memiliki nilai kosong.

#### Data Cleaning
Data cleaning adalah proses dalam analisis data yang bertujuan untuk mempersiapkan dataset agar dapat digunakan dengan lebih efektif dan akurat.
"""

all_movies_clean = all_movies.dropna()
all_movies_clean

"""Setelah proses pembersihan, jumlah data berkurang dari 285.762 baris menjadi 233.213 baris. Selanjutnya, lakukan pengecekan kembali untuk memastikan tidak ada missing value pada dataframe all_movies_clean."""

all_movies_clean.isnull().sum()

"""Mengurutkan movie berdasarkan movieId kemudian memasukkannya ke dalam variabel fixing_movies"""

fixing_movies = all_movies_clean.sort_values('movieId', ascending=True)
fixing_movies

"""Mengecek berapa jumlah fixing_movies"""

len(fixing_movies.movieId.unique())

"""Membuat variabel preparing yang berisi dataframe fixing_movies kemudian mengurutkan berdasarkan movieId"""

preparing = fixing_movies
preparing.sort_values('movieId')

"""#### Data Duplicates
Data duplicates merujuk pada kondisi di mana ada dua atau lebih baris yang identik atau sangat mirip dalam dataset.

Gunakan data unik untuk keperluan pemodelan dengan menghapus duplikat menggunakan fungsi `drop_duplicates()` berdasarkan kolom movieId.
"""

# Membuang data duplikat pada variabel preparation
preparing = preparing.drop_duplicates('movieId')
preparing

"""#### Mengkonversikan Data

Selanjutnya,  melakukan konversi data series menjadi list. Dalam hal ini, menggunakan fungsi tolist() dari library numpy. Implementasikan
"""

# Mengonversi data series ‘movieId’ menjadi dalam bentuk list
movie_id = preparing['movieId'].tolist()

# Mengonversi data series ‘title’ menjadi dalam bentuk list
movie_name = preparing['title'].tolist()

# Mengonversi data series ‘genres’ menjadi dalam bentuk list
movie_genre = preparing['genres'].tolist()

print(len(movie_id))
print(len(movie_name))
print(len(movie_genre))

"""Membuat dictionary untuk menentukan pasangan key-value pada data movie_id, movie_name, dan movie_genre yang telah disiapkan sebelumnya."""

# Membuat dictionary untuk data ‘movie_id’, ‘movie_name’, dan ‘movie_genre’
movie_new = pd.DataFrame({
    'id': movie_id,
    'movie_name': movie_name,
    'genre': movie_genre
})
movie_new

"""## 4. Modeling and Result
Proses pemodelan yang saya lakukan pada data ini mencakup penerapan algoritma machine learning, yaitu content-based filtering dan collaborative filtering.
- Pada algoritma content-based filtering, pendekatan yang digunakan didasarkan pada preferensi pengguna terhadap item yang telah mereka sukai di masa lalu.
- Sementara itu, pada collaborative filtering, model ini memanfaatkan tingkat rating yang diberikan oleh pengguna terhadap film untuk menghasilkan rekomendasi yang relevan.

### 1. Menggunakan *Content Based Filtering*

*Content-Based Filtering* adalah salah satu metode dalam sistem rekomendasi yang digunakan untuk memberikan rekomendasi kepada pengguna berdasarkan karakteristik atau atribut dari item yang telah mereka interaksikan atau sukai sebelumnya.

#### TFIDFVetorizer()
TfidfVectorizer adalah alat dari pustaka scikit-learn yang digunakan untuk mengubah teks menjadi representasi numerik berbasis TF-IDF. TF-IDF adalah teknik yang digunakan untuk menilai pentingnya kata dalam dokumen yang bersifat kolektif atau seluruh korpus.

Menggunakan TF-IDF (Term Frequency-Inverse Document Frequency) untuk memproses data teks, dalam hal ini, data genre dari film yang ada dalam dataframe movie_new.
"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Inisialisasi TfidfVectorizer
tf = TfidfVectorizer()

# Melakukan perhitungan idf pada data genre
tf.fit(movie_new['genre'])

# Mapping array dari fitur index integer ke fitur nama
feature_names = tf.get_feature_names_out()

"""Kemudian dapat melakukan fit dan transformasi ke dalam bentuk matirx"""

tfidf_matrix = tf.fit_transform(movie_new['genre'])
tfidf_matrix.shape

"""
 Menghasilkan vektor tf-idf dalam bentuk matrix, menggunakan fungsi todense()."""

tfidf_matrix.todense()

"""Lihat matrix tf-idf untuk beberapa movie (movie_name) dan genre"""

pd.DataFrame(
    tfidf_matrix.todense(),
    columns= tf.get_feature_names_out(),
    index=movie_new.movie_name
).sample(22, axis=1).sample(10, axis=0)

"""####  *Cosine Similarity*
*Cosine Similarity* adalah sebuah ukuran yang digunakan untuk menghitung seberapa mirip dua vektor dalam ruang vektor berdimensi tinggi, dengan menggunakan sudut antara kedua vektor tersebut. Meskipun vektor dapat memiliki panjang yang berbeda, Cosine Similarity mengukur kesamaan arah antara dua vektor, bukan panjangnya.
"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Membuat dataframe dari variabel cosine_sim_df dengan baris dan kolom berupa nama movie, serta melihat kesamaan matrix dari setiap movie"""

cosine_sim_df = pd.DataFrame(cosine_sim, index=movie_new['movie_name'], columns=movie_new['movie_name'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""#### Rekomendasi testing

Membuat fungsi movie_recommendations dengan beberapa parameter sebagai berikut:

- Nama_movie : Nama judul dari movie tersebut (index kemiripan dataframe).  
- Similarity_data : Dataframe mengenai similarity yang telah kita didefinisikan sebelumnya
- Items : Nama dan fitur yang digunakan untuk mendefinisikan kemiripan, dalam hal ini adalah ‘movie_name’ dan ‘genre’.  
- k : Banyak rekomendasi yang ingin diberikan.
"""

def movie_recommendations(nama_movie, similarity_data=cosine_sim_df, items=movie_new[['movie_name', 'genre']], k=5):


    # Mengambil data dengan menggunakan argpartition untuk melakukan partisi secara tidak langsung sepanjang sumbu yang diberikan
    # Dataframe diubah menjadi numpy
    # Range(start, stop, step)
    index = similarity_data.loc[:,nama_movie].to_numpy().argpartition(
        range(-1, -k, -1))

    # Mengambil data dengan similarity terbesar dari index yang ada
    closest = similarity_data.columns[index[-1:-(k+2):-1]]

    # Drop nama_movie agar nama movie yang dicari tidak muncul dalam daftar rekomendasi
    closest = closest.drop(nama_movie, errors='ignore')

    return pd.DataFrame(closest).merge(items).head(k)

"""
 Terapkan kode di atas untuk menemukan rekomendasi movie yang mirip dengan Juno (2007)."""

movie_new[movie_new.movie_name.eq('Juno (2007)')]

"""Dari hasil di atas dapat dilihat bahwa pengguna menyukai movie yang berjudul Juno (2007) yang bergenre Comedy, Drama, Romance.  
Mendapatkan rekomendasi movie yang mirip dengan Juno (2007).


"""

movie_recommendations('Juno (2007)')

"""Dari hasil rekomendasi di atas, diketahui bahwa Juno (2007) termasuk ke dalam genre Comedy|Drama|Fantasy. Menghasilkan content base filtering 4 Item yang memiliki genre Comedy|Drama|Fantasy (similiar).

### 2. Menggunakan *Collaborative Filtering*
*Collaborative Filtering* adalah teknik yang digunakan dalam sistem rekomendasi untuk memberikan rekomendasi berdasarkan preferensi atau interaksi pengguna lain. Pendekatan ini tidak bergantung pada atribut atau konten dari item itu sendiri (seperti dalam Content-Based Filtering).

#### Preparation

Mengubaah variabel rating menjadi df
"""

df = ratings

df

"""- Mengubah userID menjadi list tanpa nilai yang sama
- Melakukan encoding userID
- Melakukan proses encoding angka ke ke userID
"""

user_ids = df['userId'].unique().tolist()
print('list userID: ', user_ids)

user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
print('encoded userID : ', user_to_user_encoded)

user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
print('encoded angka ke userID: ', user_encoded_to_user)

"""Kemudian dapat melakukan hal yang sama pada features ‘movieId’."""

# Mengubah movieId menjadi list tanpa nilai yang sama
movie_ids = df['movieId'].unique().tolist()

# Melakukan proses encoding movieId
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}

# Melakukan proses encoding angka ke movieId
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}

# Selanjutnya, petakan userId dan movieId ke dataframe yang berkaitan.

# Mapping userId ke dataframe genres
df['genres'] = df['userId'].map(user_to_user_encoded)

# Mapping movieD ke dataframe movies
df['movies'] = df['movieId'].map(movie_to_movie_encoded)

"""Terakhir, periksa beberapa informasi dalam data seperti total pengguna, total film, ubah nilai rating menjadi tipe data float, serta cek nilai minimum dan maksimum."""

num_users = len(user_to_user_encoded)
print(num_users)

num_movie = len(movie_encoded_to_movie)
print(num_movie)

df['ratings'] = df['rating'].values.astype(np.float32)

min_rating = min(df['rating'])

max_rating = max(df['rating'])

print('Number of User: {}, Number of movie: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movie, min_rating, max_rating
))

"""#### Split Data for Training and Validation"""

df = df.sample(frac=1, random_state=42)

df

"""Membagi data train dan validasi dengan komposisi 80:20."""

# Membuat variabel x untuk mencocokkan data genres  dan movies menjadi satu value
x = df[['genres', 'movies']].values

# Membuat variabel y untuk membuat ratings dari hasil
y = df['ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""#### RecommenderNet"""

import tensorflow as tf
class RecommenderNet(tf.keras.Model):

  # Insialisasi fungsi
  def __init__(self, num_users, num_movie, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movie = num_movie
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding( # layer embedding user
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1) # layer embedding user bias
    self.movie_embedding = layers.Embedding( # layer embeddings movies
        num_movie,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movie_bias = layers.Embedding(num_movie, 1) # layer embedding movies bias

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0]) # memanggil layer embedding 1
    user_bias = self.user_bias(inputs[:, 0]) # memanggil layer embedding 2
    movie_vector = self.movie_embedding(inputs[:, 1]) # memanggil layer embedding 3
    movie_bias = self.movie_bias(inputs[:, 1]) # memanggil layer embedding 4

    dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)

    x = dot_user_movie + user_bias + movie_bias

    return tf.nn.sigmoid(x) # activation sigmoid

"""#### Training

Melakukan proses compile terhadap model. serta menggunakan matrix evaluasi RMSE
"""

model = RecommenderNet(num_users, num_movie, 50)

# model compile
model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Memulai proses training dengan batch size sebesar 64 serta epoch 100 kali"""

# Memulai training
history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 64,
    epochs = 100,
    validation_data = (x_val, y_val)
)

"""**Visualisasi Metrik**  
Untuk melihat visualisasi proses training
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

"""#### Rekomendasi Testing"""

movie_df = movie_new
df = pd.read_csv('/content/gdrive/MyDrive/Active/ML-TERAPAN/submission2/small-data/ratings.csv')


user_id = df.userId.sample(1).iloc[0]
movie_watched_by_user = df[df.userId == user_id]


movie_not_watched = movie_df[~movie_df['id'].isin(movie_watched_by_user.movieId.values)]['id']
movie_not_watched = list(
    set(movie_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movie_not_watched = [[movie_to_movie_encoded.get(x)] for x in movie_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movie_array = np.hstack(
    ([[user_encoder]] * len(movie_not_watched), movie_not_watched)
)

"""Untuk memperoleh rekomendasi movies, gunakan fungsi model.predict() dari library Keras dengan menerapkan kode berikut."""

ratings = model.predict(user_movie_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movie_ids = [
    movie_encoded_to_movie.get(movie_not_watched[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('movie with high ratings from user')
print('----' * 8)

top_movie_user = (
    movie_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movie_df_rows = movie_df[movie_df['id'].isin(top_movie_user)]
for row in movie_df_rows.itertuples():
    print(row.movie_name, ':', row.genre)

print('----' * 8)
print('Top 10 movie recommendation')
print('----' * 8)

recommended_movie = movie_df[movie_df['id'].isin(recommended_movie_ids)]
for row in recommended_movie.itertuples():
    print(row.movie_name, ':', row.genre)

"""Dari hasil di atas movie yang bergenre Comedy Romance menjadi movie yang paling tinggi ratingsnya. Kemudian top 10 movie yang direkomendasikan sistem adalah movie dengan genre Drama, Romance, dan Comedy."""